{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2605fd22-3570-4f23-9555-4528d3f0f9e8",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13218f7c-0b8d-4ab0-b88d-0897ce46ca63",
   "metadata": {},
   "source": [
    "Answer 1. Probability Mass Function (PMF) and Probability Density Function (PDF) are two ways of describing the probability distribution of a random variable.\n",
    "\n",
    "A probability mass function (PMF) is used for discrete random variables, and it assigns a probability to each possible outcome of the random variable. In other words, it gives the probability of a discrete random variable taking on a specific value. The sum of the probabilities for all possible outcomes is always equal to 1.\n",
    "\n",
    "For example, consider rolling a fair six-sided die. The possible outcomes are 1, 2, 3, 4, 5, and 6, and each outcome has an equal probability of 1/6.\n",
    "\n",
    "The PMF for this random variable is:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "\n",
    "P(X = 2) = 1/6\n",
    "\n",
    "P(X = 3) = 1/6\n",
    "\n",
    "P(X = 4) = 1/6\n",
    "\n",
    "P(X = 5) = 1/6\n",
    "\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "A probability density function (PDF), on the other hand, is used for continuous random variables. It describes the relative likelihood of the random variable taking on a specific value within a range of possible values. Unlike a PMF, a PDF does not give the probability of a specific outcome. Instead, it gives the probability density, which is the likelihood of a value falling within a particular range.\n",
    "\n",
    "For example, consider the height of adult females in a population. The height is a continuous random variable, and the PDF describes the relative likelihood of the height taking on a specific value. The PDF might look like a bell curve, with the peak indicating the most likely height and the width indicating the range of likely heights. The area under the curve between two values gives the probability that the height falls within that range.\n",
    "\n",
    "Overall, PMF and PDF are two different ways of describing the probability distribution of random variables, with PMF used for discrete variables and PDF used for continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c200317-8f95-4772-ad07-48fd38d07a03",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e05e85-cc74-45d2-b54c-95ef98915fb7",
   "metadata": {},
   "source": [
    "Answer 2. A cumulative density function (CDF) is a function that describes the probability that a random variable takes on a value less than or equal to a given value. It is defined for both discrete and continuous random variables.\n",
    "\n",
    "For a discrete random variable, the CDF is the sum of the probabilities of all the values less than or equal to the given value. For a continuous random variable, the CDF is the integral of the probability density function (PDF) up to the given value. In other words, the CDF gives the probability of the random variable being less than or equal to a particular value.\n",
    "\n",
    "For example, consider flipping a fair coin twice. The possible outcomes are (H,H), (H,T), (T,H), and (T,T), each with a probability of 1/4. The CDF for this random variable is:\n",
    "\n",
    "F(X ≤ 0) = 0 (since there are no outcomes with sum less than or equal to 0)\n",
    "\n",
    "F(X ≤ 1) = P(X = 0) = 1/4\n",
    "\n",
    "F(X ≤ 2) = P(X = 0) + P(X = 1) = 1/4 + 1/2 = 3/4\n",
    "\n",
    "F(X ≤ 3) = P(X = 0) + P(X = 1) + P(X = 2) = 1/4 + 1/2 + 1/4 = 1\n",
    "\n",
    "This tells us that the probability of getting a sum less than or equal to 1 is 1/4, the probability of getting a sum less than or equal to 2 is 3/4, and the probability of getting a sum less than or equal to 3 is 1.\n",
    "\n",
    "CDFs are used for a variety of purposes, including hypothesis testing, confidence intervals, and calculating percentiles. They provide a useful way to summarize the distribution of a random variable and make it easier to perform calculations involving probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53121283-8304-4152-9c83-ee5edaa19d99",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e00f589-1b65-4dd9-82bf-18b9f9c0331d",
   "metadata": {},
   "source": [
    "Answer 3. The normal distribution, also known as the Gaussian distribution or the bell curve, is a probability distribution that is commonly used to model real-world phenomena in many fields, including finance, physics, biology, and psychology.\n",
    "\n",
    "Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "1. Height and weight of people in a population\n",
    "2. Test scores in a large group of students\n",
    "3. Errors in a manufacturing process\n",
    "4. Stock prices and returns in finance\n",
    "5. IQ scores in a population\n",
    "\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean and the standard deviation. The mean represents the center of the distribution, while the standard deviation determines the width and spread of the distribution.\n",
    "\n",
    "The shape of the normal distribution is symmetric and bell-shaped, with the highest point of the curve at the mean. The standard deviation determines how spread out the distribution is, with larger standard deviations leading to wider distributions. Specifically, about 68% of the data falls within one standard deviation of the mean, about 95% falls within two standard deviations, and about 99.7% falls within three standard deviations.\n",
    "\n",
    "In mathematical terms, the probability density function (PDF) of the normal distribution is given by:\n",
    "\n",
    "f(x) = (1/σ√(2π)) * e^(-((x-μ)^2)/(2σ^2))\n",
    "\n",
    "where μ is the mean and σ is the standard deviation. The parameters μ and σ determine the location and spread of the distribution, respectively.\n",
    "\n",
    "\n",
    "Overall, the normal distribution is a versatile and widely used tool for modeling real-world phenomena, thanks to its simplicity and useful properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f9c9e-1cc9-4969-9853-cfff8d820d6c",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e57ba-bd2a-4dd8-88ec-4bbd8794ab0f",
   "metadata": {},
   "source": [
    "Answer 4. The normal distribution is one of the most important and widely used probability distributions in statistics and data analysis. It is important for several reasons:\n",
    "\n",
    "1. It is a mathematical model that approximates many natural phenomena and real-world processes, making it a useful tool for scientists and researchers to study and understand complex systems.\n",
    "\n",
    "2. It provides a simple and intuitive way to describe the distribution of a dataset, using just two parameters - the mean and standard deviation - which can help researchers and decision-makers summarize and visualize large amounts of data.\n",
    "\n",
    "3. It plays a key role in many statistical methods, including hypothesis testing, confidence intervals, and regression analysis, making it a fundamental concept in statistical theory and practice.\n",
    "\n",
    "\n",
    "**Some real-life examples of normal distribution include:**\n",
    "\n",
    "1. Heights and weights of people in a population - the distribution of heights and weights in a large population typically follows a normal distribution.\n",
    "\n",
    "2. IQ scores - IQ scores in a population tend to be normally distributed, with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "3. Test scores - the distribution of test scores in a large group of students often follows a normal distribution.\n",
    "\n",
    "4. Errors in manufacturing processes - the variation in measurements and errors in a manufacturing process can often be modeled using a normal distribution.\n",
    "\n",
    "5. Financial returns - the returns of many financial assets, such as stocks, are often assumed to follow a normal distribution, which is used in many financial models and risk management strategies.\n",
    "\n",
    "In summary, the normal distribution is a powerful and versatile tool that is used in many different fields to model and analyze complex systems and data. Its importance stems from its usefulness as a mathematical model, its simplicity in describing data, and its ubiquity in statistical methods and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3247b4d1-eb2d-4434-a82a-8be8a73cd730",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76103e24-1c4f-4f41-bfa9-34dbf2dde588",
   "metadata": {},
   "source": [
    "Answer 5. The Bernoulli distribution is a probability distribution that describes the outcomes of a single binary experiment or trial, where there are only two possible outcomes - success or failure. The distribution is named after Swiss mathematician Jakob Bernoulli, who studied the concept in the 17th century.\n",
    "\n",
    "The Bernoulli distribution is characterized by a single parameter p, which represents the probability of success. The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "P(X = 1) = p\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "**Where X is a random variable representing the outcome of the experiment.**\n",
    "\n",
    "An example of the Bernoulli distribution is flipping a coin, where success might be defined as getting heads and failure might be defined as getting tails. In this case, the probability of success (getting heads) is p=0.5 and the probability of failure (getting tails) is 1-p=0.5.\n",
    "\n",
    "The Binomial distribution, on the other hand, is a probability distribution that describes the number of successes in a fixed number of independent Bernoulli trials. It is characterized by two parameters - the number of trials n, and the probability of success in each trial p. The PMF of the Binomial distribution is:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where X is a random variable representing the number of successes in n trials, k is the number of successes, and (n choose k) is the binomial coefficient.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the Binomial distribution is that the Bernoulli distribution describes the outcome of a single trial, while the Binomial distribution describes the number of successes in multiple trials. The Bernoulli distribution can be seen as a special case of the Binomial distribution, where n=1.\n",
    "\n",
    "An example of the Binomial distribution is rolling a die multiple times and counting the number of times a particular number comes up. If we define success as rolling a 3, then the probability of success in each trial is p=1/6, and the number of trials is n. The Binomial distribution can then be used to calculate the probability of getting k 3's in n rolls of the die."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11485235-9944-4766-9830-bc0693f912bd",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54bd80e-e5b2-4df0-b68e-7778d414b7c4",
   "metadata": {},
   "source": [
    "Answer 6.\n",
    "\n",
    "Given:\n",
    "Mean (μ) = 50\n",
    "Standard deviation (σ) = 10\n",
    "Value to find probability for (x) = 60\n",
    "\n",
    "We need to find the probability of getting a value greater than 60 from a normally distributed dataset with mean 50 and standard deviation 10.\n",
    "\n",
    "Using the z-score formula, we can convert the value x to its corresponding \n",
    "z-score:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "z = (60 - 50) / 10\n",
    "z = 1\n",
    "\n",
    "Now we can use a z-table or a calculator to find the probability of getting a z-score greater than 1. The area to the right of z = 1 is the probability of getting a value greater than 60.\n",
    "\n",
    "Using a standard normal distribution table or calculator, we find that the probability of getting a z-score greater than 1 is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from the given dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7783311-2385-4c86-a656-d14b08711cef",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131b283-5faa-4ef2-ba1d-f16763192b23",
   "metadata": {},
   "source": [
    "Answer7. The uniform distribution is a probability distribution that describes a situation where all possible outcomes are equally likely to occur. This means that the probability of any given outcome is the same as the probability of any other outcome.\n",
    "\n",
    "In other words, if we have a continuous uniform distribution on the interval [a,b], every value in that interval has the same probability of being selected.\n",
    "\n",
    "The probability density function (PDF) of a continuous uniform distribution on the interval [a,b] is:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "= 0 otherwise\n",
    "\n",
    "This means that the probability of selecting any value between a and b is equal to 1/(b-a).\n",
    "\n",
    "An example of the uniform distribution is rolling a fair die. Since there are six equally likely outcomes (the numbers 1 through 6), the probability of rolling any one of those numbers is 1/6. If we let X be the random variable representing the outcome of rolling the die, then the probability distribution of X is uniform on the interval [1,6].\n",
    "\n",
    "Another example of the uniform distribution is selecting a random number from a certain range, such as picking a random number between 1 and 10. In this case, any number between 1 and 10 has an equal chance of being selected, and the probability distribution of the selected number is uniform on the interval [1,10]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d6de9-2005-4342-83a7-c7c73798b702",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68bd6dc-a73e-4eb1-91f2-097cd21a49ad",
   "metadata": {},
   "source": [
    "Answer 8. The z-score (also known as the standard score) is a statistical measure that represents the number of standard deviations an observation or data point is from the mean of a dataset. It is a way of standardizing data so that different datasets can be compared on a common scale.\n",
    "\n",
    "The formula for calculating the z-score of an observation x from a dataset with mean μ and standard deviation σ is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "The z-score indicates how many standard deviations an observation is away from the mean. A positive z-score means the observation is above the mean, while a negative z-score means the observation is below the mean. A z-score of 0 means the observation is equal to the mean.\n",
    "\n",
    "The importance of the z-score lies in its ability to help us compare observations from different datasets that may have different scales or units of measurement. By standardizing the data, we can easily see how an observation in one dataset compares to the rest of the dataset, or to observations in another dataset.\n",
    "\n",
    "The z-score is also used to calculate probabilities in the standard normal distribution. The standard normal distribution has a mean of 0 and a standard deviation of 1, and the z-score formula can be used to convert any observation from a normal distribution to its corresponding z-score. By using a standard normal distribution table or calculator, we can find the probability of getting an observation with a certain z-score or greater, which can be useful in statistical hypothesis testing and confidence interval estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e545a4d-a9d6-4af8-b582-02af0faf8084",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf79d7-e4b2-4492-b9cb-89516cc82688",
   "metadata": {},
   "source": [
    "Answer 9. The Central Limit Theorem (CLT) is a fundamental theorem in statistics that states that the distribution of the sample mean of a large number of independent and identically distributed (i.i.d) random variables approaches a normal distribution, regardless of the underlying distribution of the population.\n",
    "\n",
    "More formally, if we take random samples of size n from any population with mean μ and standard deviation σ, the distribution of the sample means will approach a normal distribution with mean μ and standard deviation σ/√n as n gets larger. This holds true even if the original population distribution is not normally distributed.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it provides a foundation for statistical inference and hypothesis testing, which are key aspects of many fields in science, engineering, and social sciences. In particular, the theorem allows us to make inferences about the population mean and variance using sample statistics, even if the population distribution is unknown or non-normal.\n",
    "\n",
    "For example, the CLT can be used to estimate the mean of a population by taking multiple random samples of the same size and calculating their means. The distribution of these sample means will approximate a normal distribution, allowing us to calculate the confidence interval and test hypotheses about the population mean.\n",
    "\n",
    "Overall, the Central Limit Theorem is a cornerstone of statistical theory and has wide-ranging applications in many fields. It allows us to use the principles of probability and statistics to make sense of data from real-world scenarios, even when the underlying population distribution is not well-understood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7313ee0-9849-4034-9667-076e9fd66290",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fc0863-95f1-4fcc-a702-9154ad372ac8",
   "metadata": {},
   "source": [
    "Answer 10. The Central Limit Theorem (CLT) has certain assumptions that must be met in order for it to be valid.\n",
    "\n",
    "These assumptions are:\n",
    "\n",
    "1. **Independence:** The random samples must be independent of each other. Each sample must be selected randomly and without bias, and the outcome of one sample should not affect the outcome of any other sample.\n",
    "\n",
    "2. **Sample size:** The sample size should be sufficiently large. In general, a sample size of at least 30 is considered sufficient, although this can vary depending on the distribution of the population.\n",
    "\n",
    "3. **Finite variance:** The population from which the samples are drawn should have a finite variance. If the variance is infinite, the CLT may not hold.\n",
    "\n",
    "4. **Identically distributed:** The samples must be identically distributed, meaning that they are drawn from the same population with the same mean and variance.\n",
    "\n",
    "If these assumptions are met, the Central Limit Theorem can be used to approximate the distribution of the sample means using a normal distribution. However, if any of these assumptions are violated, the CLT may not be valid and alternative methods of analysis may need to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f97ed-a0b9-44f4-8294-faff8fc728ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
